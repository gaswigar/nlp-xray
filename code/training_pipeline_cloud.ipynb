{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4cf47ee-334d-46f1-80db-6983245a33bd",
   "metadata": {},
   "source": [
    "### Training Pipeline Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f22040b4-d928-4516-8b3a-d09bd9402b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    " \n",
    "REGION = 'us-central1'\n",
    "PROJECT = !(gcloud config get-value core/project)\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET =  'nlp-xray-dataset'\n",
    "\n",
    "# # Do not change these\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f302ce85-2f13-4d95-8089-9fedc8a88bc6",
   "metadata": {},
   "source": [
    "### Task setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2220d6f9-91e6-4738-921d-d22d94e90641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting xray_models/trainer_cloud/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile xray_models/trainer_cloud/task.py\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "from . import model\n",
    "\n",
    "def _parse_arguments(argv):\n",
    "    \"\"\"\n",
    "    Parse command line arguments\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--model_type',\n",
    "        help='which model type to use',\n",
    "        type=str, default='mobilenetv2')\n",
    "    parser.add_argument(\n",
    "        '--epoch',\n",
    "        help='number of epochs to use',\n",
    "        type=int, default=5)\n",
    "    parser.add_argument(\n",
    "        '--steps_per_epoch',\n",
    "        help='number of steps per epoch to use',\n",
    "        type=int, default=10)\n",
    "    parser.add_argument(\n",
    "        '--job_dir',\n",
    "        help='directory where to save the model',\n",
    "        type=str, default='xray_models/')\n",
    "    parser.add_argument(\n",
    "        '--nrows',\n",
    "        help='number of total rows desired accross test, validation, and test set',\n",
    "        type=int, default=None)\n",
    "    parser.add_argument('--loss_class_weighted', dest='loss_class_weighted', action='store_true')\n",
    "    parser.add_argument('--loss_not_class_weighted', dest='loss_class_weighted', action='store_false')\n",
    "    parser.set_defaults(loss_class_weighted=True)\n",
    "    return parser.parse_known_args(argv)\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    This function will parse command line arguments and kick model training\n",
    "    \"\"\"\n",
    "    args = _parse_arguments(sys.argv[1:])[0]\n",
    "    print(f'Training with Arguments:{args}')\n",
    "    trial_id = json.loads(\n",
    "        os.environ.get('TF_CONFIG', '{}')).get('task', {}).get('trial', '')\n",
    "    output_path = args.job_dir if not trial_id else args.job_dir+'/'\n",
    "    \n",
    "    model_layers = model.get_layers(args.model_type)\n",
    "    model_history = model.train_and_evaluate(model_layers,args.epoch, args.steps_per_epoch, args.job_dir, args.nrows, args.loss_class_weighted, args.model_type)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f4c8b-58ef-46ba-91c3-735cbdc0d053",
   "metadata": {},
   "source": [
    "### Adding non model functions to a config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd1baee7-6a57-4da5-8578-a449f9aa17a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting xray_models/trainer_cloud/config/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile xray_models/trainer_cloud/config/config.py\n",
    "\n",
    "#model parameters\n",
    "IMG_HEIGHT = 299\n",
    "IMG_WIDTH = 299\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "processing_parameters={'mobilenetv2': {'channels': 1, 'image_height': min([IMG_HEIGHT,299]), 'image_width': min([IMG_WIDTH,299]), 'pixel_scale_min': 0, 'pixel_scale_max': 1}, \n",
    "                           'cnn': {'channels': 1, 'image_height': min([IMG_HEIGHT,299]), 'image_width': min([IMG_WIDTH,299]), 'pixel_scale_min': 0, 'pixel_scale_max': 1}, \n",
    "                           'inception_resnet': {'channels': 3, 'image_height': 299, 'image_width': 299, 'pixel_scale_min': 0, 'pixel_scale_max': 1}, \n",
    "                           'vision_transformer': {'channels': 3, 'image_height': 224, 'image_width': 224, 'pixel_scale_min': -1, 'pixel_scale_max': 1}}\n",
    "BATCH_SIZE = 20\n",
    "SHUFFLE_BUFFER = 20*BATCH_SIZE\n",
    "\n",
    "VAL_BATCH_SIZE = 100\n",
    "VALIDATION_IMAGES = 10000\n",
    "VALIDATION_STEPS = VALIDATION_IMAGES//BATCH_SIZE\n",
    "\n",
    "#augmentation parameters\n",
    "MAX_DELTA = 63.0/255.0 #adjusting brightness\n",
    "CONTRAST_LOWER = 0.2\n",
    "CONTRAST_UPPER = 1.8\n",
    "\n",
    "#response variable columns in the mete_data_processed.csv\n",
    "response_variables = ['atelectasis', 'cardiomegaly', 'consolidation', 'edema', 'effusion', 'emphysema', 'fibrosis', 'hernia',\n",
    "                 'infiltration', 'mass', 'no_finding', 'nodule', 'pleural_thickening', 'pneumonia', 'pneumothorax']\n",
    "\n",
    "meta_data_train_processed_path = \"gs://nlp-xray-dataset/meta_data/meta_data_processed_train.csv\" #location to the meta data file - train \n",
    "meta_data_val_processed_path = \"gs://nlp-xray-dataset/meta_data/meta_data_processed_val.csv\" #location to the meta data file - val\n",
    "meta_data_test_processed_path = \"gs://nlp-xray-dataset/meta_data/meta_data_processed_test.csv\" #location to the meta data file - test\n",
    "meta_data_processed_path = \"gs://nlp-xray-dataset/meta_data/meta_data_processed.csv\" #location to the meta data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8750cd6-b1d7-46a5-8783-a1397cfd2369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting xray_models/trainer_cloud/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile xray_models/trainer_cloud/preprocessing.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from .config import config\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def rescale_image_tensor(t,domain_interval,range_interval):\n",
    "    a=domain_interval[0]\n",
    "    b=domain_interval[1]\n",
    "    c=range_interval[0]\n",
    "    d=range_interval[1]\n",
    "    rescaled_t=c+((d-c)/(b-a))*(t-a)\n",
    "    return(rescaled_t)\n",
    "\n",
    "def decode_image(img, reshape_dims, num_channels, pixel_min, pixel_max):\n",
    "    \"\"\"\n",
    "    Decode an image\n",
    "    \"\"\"\n",
    "    img = tf.image.decode_png(img, channels=num_channels)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, reshape_dims)\n",
    "    image_min = tf.math.reduce_min(img)\n",
    "    image_max = tf.math.reduce_max(img)    \n",
    "    if pixel_min!=image_min and pixel_max!=image_max:\n",
    "        #img=img.map(lambda x: tf.py_function(func=rescale_image_tensor, inp=[x, [image_min,image_max],[pixel_min,pixel_max]], Tout=tf.float32))\n",
    "        #img = img.map(lambda x: rescale_image_tensor(x,[image_min,image_max],[pixel_min,pixel_max]))\n",
    "        img = rescale_image_tensor(img, [image_min,image_max],[pixel_min,pixel_max])\n",
    "    img = tf.cast(img, dtype=tf.float32)\n",
    "    return(img)\n",
    "\n",
    "def decode(filename, label):\n",
    "    \"\"\"\n",
    "    Decode file names.\n",
    "    \"\"\"\n",
    "    image_bytes = tf.io.read_file(filename=filename)\n",
    "    return image_bytes, label\n",
    "\n",
    "\n",
    "def get_filenames_and_labels(data_path,nrow_ind):\n",
    "    \"\"\"\n",
    "    Get filenames and labels\n",
    "    \"\"\"\n",
    "    meta_data = pd.read_csv(data_path)\n",
    "    all_files = meta_data['gs_path'].tolist()\n",
    "    response_vars = config.response_variables    \n",
    "    all_labels = np.array(meta_data[response_vars].values.tolist())\n",
    "    if nrow_ind:\n",
    "        if nrow_ind<= meta_data.shape[0]:            \n",
    "            zip_lists=list(zip(all_files, all_labels))\n",
    "            random.shuffle(zip_lists)\n",
    "            files, labels = zip(*zip_lists)\n",
    "            files=list(files)[:nrow_ind]\n",
    "            labels=np.array(labels)[:nrow_ind]\n",
    "            return(files, labels)\n",
    "        else:\n",
    "            return(all_files, all_labels)\n",
    "    else: \n",
    "        return(all_files, all_labels)\n",
    "\n",
    "        \n",
    "\n",
    "def read_and_preprocess(image_bytes, label,model_type='cnn', random_augment=False):\n",
    "    \"\"\"\n",
    "    Function which performs data augmentation.\n",
    "    \"\"\"\n",
    "    pp=config.processing_parameters[model_type]\n",
    "    if random_augment:\n",
    "        img = decode_image(image_bytes, [pp['image_width']+10,pp['image_width']+10], pp['channels'], pp['pixel_scale_min'], pp['pixel_scale_max'])\n",
    "        img = tf.image.random_crop(img, [config.IMG_HEIGHT, config.IMG_WIDTH, config.IMG_CHANNELS])\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_brightness(img, config.MAX_DELTA)\n",
    "        img = tf.image.random_contrast(img, config.CONTRAST_LOWER, config.CONTRAST_UPPER)\n",
    "    else:\n",
    "        img = decode_image(image_bytes, [pp['image_width'],pp['image_width']], pp['channels'], pp['pixel_scale_min'], pp['pixel_scale_max'])\n",
    "    return img, label\n",
    "\n",
    "def read_and_preprocess_with_augment(image_bytes, label, model_type='cnn'):\n",
    "    \"\"\"\n",
    "    Data augmentation for the training set.\n",
    "    \"\"\"\n",
    "    return read_and_preprocess(image_bytes, label, model_type, random_augment=True)\n",
    "\n",
    "\n",
    "# UPDATE HERE\n",
    "def load_dataset(filenames, labels, batch_size,model_type, training=True):\n",
    "    \"\"\"\n",
    "    This functions load the dataset from the GCS bucket.\n",
    "    Inputs include:\n",
    "    filenames: list of gcs locations for image files\n",
    "    labels: numpy array of one hot encoded multi labels\n",
    "    batch_size: batch size\n",
    "    training: boolean entry specifying if training data is needed. False for test data.\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels)).map(decode) #numpy array of filenames and numpy array of labels    \n",
    "    if training:\n",
    "        dataset = dataset.map(lambda f,l: read_and_preprocess_with_augment(f,l,model_type=model_type)).cache().shuffle(config.SHUFFLE_BUFFER).repeat(count=None)\n",
    "    else:\n",
    "        dataset = dataset.map(lambda f,l: read_and_preprocess(f,l,model_type=model_type)).repeat(count=1)\n",
    "    \n",
    "    return dataset.batch(batch_size=batch_size).prefetch(buffer_size=AUTOTUNE) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf5316c-ccb2-4cdb-9ec8-85c8eed2d8e0",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e7407eb-aff4-40a2-9af6-b4b34209c263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting xray_models/trainer_cloud/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile xray_models/trainer_cloud/model.py\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import (Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Softmax)\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from .config import config\n",
    "from .import preprocessing\n",
    "\n",
    "def get_layers(model_type, \n",
    "               nclasses=15, \n",
    "               hidden_layer_1_neurons=400,\n",
    "               hidden_layer_2_neurons=100,\n",
    "               dropout_rate=0.25,\n",
    "               num_filters_1=64,\n",
    "               kernel_size_1=3,\n",
    "               pooling_size_1=2,\n",
    "               num_filters_2=32,\n",
    "               kernel_size_2=3,\n",
    "               pooling_size_2=2):\n",
    "    \"\"\"\n",
    "    Get model layers for a specific model\n",
    "    \"\"\"\n",
    "    model_layers = {\n",
    "        'cnn':[\n",
    "            Conv2D(num_filters_1, kernel_size=kernel_size_1,\n",
    "                  activation='relu', input_shape=(config.IMG_WIDTH, config.IMG_HEIGHT, 1)),\n",
    "            MaxPooling2D(pooling_size_1),\n",
    "            Conv2D(num_filters_2, kernel_size=kernel_size_2,\n",
    "                  activation='relu'),\n",
    "            MaxPooling2D(pooling_size_2),\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_neurons, activation='relu'),\n",
    "            Dense(hidden_layer_2_neurons, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(nclasses, activation='sigmoid')\n",
    "        ],\n",
    "        'vision_transformer':\n",
    "        [hub.KerasLayer(\"https://tfhub.dev/sayakpaul/vit_b16_fe/1\", trainable=False),\n",
    "        Dense(nclasses, activation='sigmoid')\n",
    "        ],\n",
    "        'inception_resnet':[\n",
    "        hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_101/feature_vector/5\",trainable=False),\n",
    "        Dense(nclasses, activation='sigmoid')]\n",
    "        \n",
    "    }\n",
    "    return model_layers[model_type]\n",
    "\n",
    "def label_weighted_cross_entropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Loss \n",
    "    \"\"\"\n",
    "    P = tf.reduce_sum(y_true)\n",
    "    N = -1 * tf.reduce_sum(y_true - 1)\n",
    "    \n",
    "    beta_P = tf.cast((P + N) / P, dtype=tf.float64)\n",
    "    beta_N = tf.cast((P + N) / N, dtype=tf.float64)\n",
    "    \n",
    "    y_true = tf.cast(y_true, dtype=tf.float64)\n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float64)\n",
    "    \n",
    "    epsilon = tf.constant(1e-7, dtype=tf.float64) #avoid nans\n",
    "    loss = (beta_P*tf.math.log(y_pred+epsilon)*y_true + beta_N*tf.math.log((1-y_pred)+epsilon) * (1-y_true))*-1.0\n",
    "    tf.debugging.assert_all_finite(loss, 'There are nan values')\n",
    "    return tf.reduce_sum(tf.reduce_mean(loss, axis = 0))\n",
    "\n",
    "\n",
    "class ClassImbalanceSparsityAdjustedLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, inverse_class_weights):\n",
    "        \"\"\"\n",
    "        Initialization of inverse class weights\n",
    "        \"\"\"\n",
    "        super().__init__(name = 'ClassImbalanceSparsityAdjustedLoss')\n",
    "        self.inverse_class_weights = inverse_class_weights\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Cross entropy loss adjusted for class imabalance and one-hot encoding sparsity\n",
    "        \"\"\"\n",
    "        P = tf.reduce_sum(y_true)\n",
    "        N = -1 * tf.reduce_sum(y_true - 1)\n",
    "\n",
    "        beta_P = tf.cast((P + N) / P, dtype=tf.float64)\n",
    "        beta_N = tf.cast((P + N) / N, dtype=tf.float64)\n",
    "\n",
    "        y_true = tf.cast(y_true, dtype=tf.float64)\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float64)\n",
    "\n",
    "        epsilon = tf.constant(1e-7, dtype=tf.float64) #avoid nans\n",
    "        loss = (beta_P*tf.math.log(y_pred+epsilon)*y_true + beta_N*tf.math.log((1-y_pred)+epsilon) * (1-y_true))*-1.0\n",
    "        tf.debugging.assert_all_finite(loss, 'There are nan values')\n",
    "        return tf.reduce_sum(tf.reduce_mean(loss, axis = 0)*self.inverse_class_weights) \n",
    "\n",
    "\n",
    "def build_model(layers, output_dir,inverse_class_weights, loss_class_weighted):\n",
    "    \"\"\"\n",
    "    Compiles keras model for image classification/\n",
    "    \"\"\"    \n",
    "    recall = tf.keras.metrics.Recall()\n",
    "    precision = tf.keras.metrics.Precision()\n",
    "    \n",
    "    #original_loss_func - label_weighted_cross_entropy\n",
    "    model = Sequential(layers)\n",
    "    if loss_class_weighted: \n",
    "        model.compile(optimizer='adam',\n",
    "                     loss=ClassImbalanceSparsityAdjustedLoss(inverse_class_weights),\n",
    "                     metrics=[recall, precision, 'accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer='adam',\n",
    "                     loss=label_weighted_cross_entropy,\n",
    "                     metrics=[recall, precision, 'accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(model_layers,num_epochs, steps_per_epoch, output_dir, nrows, loss_class_weighted, model_type):\n",
    "    \"\"\"\n",
    "    Compile the model and load data for training into it.\n",
    "    \"\"\"\n",
    "    if nrows: \n",
    "        train_nrow=int(nrows*.8)\n",
    "        val_nrow=int(nrows*.2)\n",
    "    else: \n",
    "        train_nrow=None\n",
    "        val_nrow=None\n",
    "    \n",
    "    # Training Dataset \n",
    "    train_filenames, train_labels  = preprocessing.get_filenames_and_labels(config.meta_data_train_processed_path, \n",
    "                                                                            nrow_ind=train_nrow)\n",
    "    # CALCULATE WEIGHTS HERE \n",
    "    labels_df = pd.DataFrame(train_labels,columns=config.response_variables)\n",
    "    total = labels_df.sum(axis=0).sum()\n",
    "    inverse_props = 1/labels_df.sum(axis=0).div(total)\n",
    "    normalized_inverse_props = inverse_props.div(inverse_props.sum())\n",
    "    inverse_class_weights=np.array(normalized_inverse_props)\n",
    "    \n",
    "    # Validation Dataset\n",
    "    val_filenames, val_labels  = preprocessing.get_filenames_and_labels(config.meta_data_val_processed_path,\n",
    "                                                                            nrow_ind=val_nrow)\n",
    "    \n",
    "    model = build_model(model_layers, output_dir=output_dir, inverse_class_weights=inverse_class_weights, loss_class_weighted=loss_class_weighted)\n",
    "\n",
    "    print(f'Number of Training Records:{len(train_filenames)}')\n",
    "    print(f'Number of Validation Records:{len(val_filenames)}')\n",
    "    \n",
    "    #create training and validation data\n",
    "    train_ds = preprocessing.load_dataset(train_filenames, train_labels, config.BATCH_SIZE, model_type)\n",
    "    val_ds = preprocessing.load_dataset(val_filenames, val_labels, config.VAL_BATCH_SIZE, model_type,training=False)\n",
    "    \n",
    "    callbacks = []\n",
    "    if output_dir:\n",
    "        tensorboard_callback = TensorBoard(log_dir=output_dir)\n",
    "        callbacks = [tensorboard_callback]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "    \n",
    "    if output_dir:\n",
    "        export_path = os.path.join(output_dir, 'keras_export')\n",
    "        model.save(export_path, save_format='tf')\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f872ba-b5b0-498a-ae08-ca45955356c9",
   "metadata": {},
   "source": [
    "# Running Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c76f9c27-d565-45d2-a264-30703296e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#model_type = 'inception_resnet'\n",
    "model_type = 'cnn'\n",
    "\n",
    "os.environ[\"MODEL_TYPE\"] = model_type\n",
    "os.environ[\"JOB_DIR\"] = f\"xray_models/models/{model_type}_{current_time}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51026595-789c-4ddf-b6cc-cc4fa1019d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Arguments:Namespace(epoch=5, job_dir='xray_models/', loss_class_weighted=True, model_type='cnn', nrows=None, steps_per_epoch=100)\n",
      "Number of Training Records:68973\n",
      "Number of Validation Records:17551\n",
      "Epoch 1/5\n",
      "100/100 - 328s - loss: 0.4862 - recall: 0.6182 - precision: 0.1861 - accuracy: 0.2650 - val_loss: 0.3988 - val_recall: 0.6388 - val_precision: 0.3291 - val_accuracy: 0.5720\n",
      "Epoch 2/5\n",
      "100/100 - 307s - loss: 0.5682 - recall: 0.6940 - precision: 0.2283 - accuracy: 0.5130 - val_loss: 0.3955 - val_recall: 0.6909 - val_precision: 0.2787 - val_accuracy: 0.5803\n",
      "Epoch 3/5\n",
      "100/100 - 296s - loss: 0.4616 - recall: 0.7194 - precision: 0.2547 - accuracy: 0.6190 - val_loss: 0.3925 - val_recall: 0.6128 - val_precision: 0.3708 - val_accuracy: 0.5803\n",
      "Epoch 4/5\n",
      "100/100 - 286s - loss: 0.3577 - recall: 0.7055 - precision: 0.2701 - accuracy: 0.6490 - val_loss: 0.3806 - val_recall: 0.5626 - val_precision: 0.3401 - val_accuracy: 0.5803\n",
      "Epoch 5/5\n",
      "100/100 - 289s - loss: 0.4113 - recall: 0.7154 - precision: 0.2558 - accuracy: 0.6135 - val_loss: 0.3849 - val_recall: 0.7903 - val_precision: 0.1934 - val_accuracy: 0.5803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 21:15:53.448695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 21:15:53.458003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 21:15:53.458701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 21:15:53.459597: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-03 21:15:53.460185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 21:15:53.460873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 21:15:53.461516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 21:15:53.951001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 21:15:53.951684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 21:15:53.952296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-03 21:15:53.952872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13839 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2021-11-03 21:16:04.480582: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-03 21:16:04.480626: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-11-03 21:16:04.480656: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 1 GPUs\n",
      "2021-11-03 21:16:04.580249: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-03 21:16:04.580467: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
      "2021-11-03 21:16:05.411440: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-03 21:16:05.841681: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n",
      "2021-11-03 21:16:14.564717: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n",
      "2021-11-03 21:16:16.823003: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-03 21:16:16.823042: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-11-03 21:16:17.244940: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-11-03 21:16:17.245351: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
      "2021-11-03 21:16:17.375896: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 189 callback api events and 188 activity events. \n",
      "2021-11-03 21:16:17.383664: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-03 21:16:17.391181: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: xray_models/train/plugins/profile/2021_11_03_21_16_17\n",
      "\n",
      "2021-11-03 21:16:17.401631: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to xray_models/train/plugins/profile/2021_11_03_21_16_17/nlp-xray-notebook.trace.json.gz\n",
      "2021-11-03 21:16:17.419522: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: xray_models/train/plugins/profile/2021_11_03_21_16_17\n",
      "\n",
      "2021-11-03 21:16:17.421463: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to xray_models/train/plugins/profile/2021_11_03_21_16_17/nlp-xray-notebook.memory_profile.json.gz\n",
      "2021-11-03 21:16:17.422011: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: xray_models/train/plugins/profile/2021_11_03_21_16_17\n",
      "Dumped tool data for xplane.pb to xray_models/train/plugins/profile/2021_11_03_21_16_17/nlp-xray-notebook.xplane.pb\n",
      "Dumped tool data for overview_page.pb to xray_models/train/plugins/profile/2021_11_03_21_16_17/nlp-xray-notebook.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to xray_models/train/plugins/profile/2021_11_03_21_16_17/nlp-xray-notebook.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to xray_models/train/plugins/profile/2021_11_03_21_16_17/nlp-xray-notebook.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to xray_models/train/plugins/profile/2021_11_03_21_16_17/nlp-xray-notebook.kernel_stats.pb\n",
      "\n",
      "2021-11-03 21:31:47.065482: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n",
      "2021-11-03 21:41:11.114231: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-11-03 21:41:11.503941: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 -m xray_models.trainer_cloud.task \\\n",
    "    --job-dir=$JOB_DIR \\\n",
    "    --epochs=5 \\\n",
    "    --steps_per_epoch=100 \\\n",
    "    --model_type=$MODEL_TYPE\\\n",
    "    --loss_class_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a353efde-20c4-43a0-b613-cffc4a325491",
   "metadata": {},
   "source": [
    "# Uploading Model to the Cloud for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8821614-51e7-4261-92ad-8b7d169578fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/jupyter/nlp-xray/code/xray_models/trainer_cloud/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/jupyter/nlp-xray/code/xray_models/trainer_cloud/setup.py\n",
    "from setuptools import find_packages\n",
    "from setuptools import setup\n",
    "\n",
    "setup(\n",
    "    name='chest_xray',\n",
    "    version='0.1',\n",
    "    packages=find_packages(),\n",
    "    include_package_data=True,\n",
    "    description='Using vision to detect diseases present in chest x-rays'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c94174c8-2bff-45b6-adbb-35a89375d082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing chest_xray.egg-info/PKG-INFO\n",
      "writing dependency_links to chest_xray.egg-info/dependency_links.txt\n",
      "writing top-level names to chest_xray.egg-info/top_level.txt\n",
      "reading manifest file 'chest_xray.egg-info/SOURCES.txt'\n",
      "writing manifest file 'chest_xray.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating chest_xray-0.1\n",
      "creating chest_xray-0.1/chest_xray.egg-info\n",
      "creating chest_xray-0.1/config\n",
      "creating chest_xray-0.1/trainer\n",
      "creating chest_xray-0.1/trainer/config\n",
      "copying files to chest_xray-0.1...\n",
      "copying README.md -> chest_xray-0.1\n",
      "copying setup.py -> chest_xray-0.1\n",
      "copying chest_xray.egg-info/PKG-INFO -> chest_xray-0.1/chest_xray.egg-info\n",
      "copying chest_xray.egg-info/SOURCES.txt -> chest_xray-0.1/chest_xray.egg-info\n",
      "copying chest_xray.egg-info/dependency_links.txt -> chest_xray-0.1/chest_xray.egg-info\n",
      "copying chest_xray.egg-info/top_level.txt -> chest_xray-0.1/chest_xray.egg-info\n",
      "copying config/__init__.py -> chest_xray-0.1/config\n",
      "copying config/config.py -> chest_xray-0.1/config\n",
      "copying trainer/__init__.py -> chest_xray-0.1/trainer\n",
      "copying trainer/model.py -> chest_xray-0.1/trainer\n",
      "copying trainer/preprocessing.py -> chest_xray-0.1/trainer\n",
      "copying trainer/task.py -> chest_xray-0.1/trainer\n",
      "copying trainer/config/__init__.py -> chest_xray-0.1/trainer/config\n",
      "copying trainer/config/config.py -> chest_xray-0.1/trainer/config\n",
      "Writing chest_xray-0.1/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'chest_xray-0.1' (and everything under it)\n",
      "README.md\n",
      "__init__.py\n",
      "__pycache__\n",
      "chest_xray.egg-info\n",
      "config\n",
      "dist\n",
      "model.py\n",
      "preprocessing.py\n",
      "setup.py\n",
      "task.py\n",
      "trainer\n",
      "untitled.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "Copying file://./dist/chest_xray-0.1.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  4.6 KiB/  4.6 KiB]                                                \n",
      "Operation completed over 1 objects/4.6 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd xray_models/trainer_cloud\n",
    "python ./setup.py sdist --formats=gztar\n",
    "ls\n",
    "gsutil cp ./dist/chest_xray-0.1.tar.gz gs://${BUCKET}/cloud_training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4749c2c0-afec-4cd2-9978-2d0d6f1dd2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_type = 'cnn'\n",
    "\n",
    "os.environ[\"MODEL_TYPE\"] = model_type\n",
    "os.environ[\"JOB_DIR\"] = \"gs://{}/chest_xray_{}_{}/\".format(\n",
    "    BUCKET, model_type, current_time)\n",
    "os.environ[\"JOB_NAME\"] = \"chest_xray_{}_{}\".format(\n",
    "    model_type, current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1d83112-7ac5-4656-966e-bbc79f81a22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://nlp-xray-dataset/chest_xray_cnn_20211103_170709/'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"JOB_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "020dd423-1ebc-4976-96ac-146bc3feaab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://nlp-xray-dataset/chest_xray_cnn_20211103_170709/ us-central1 chest_xray_cnn_20211103_170709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "ERROR: (gcloud.ai.custom-jobs.create) INVALID_ARGUMENT: List of found errors:\t1.Field: job_spec.worker_pool_specs[0].machine_spec.accelerator_count; Message: Accelerators are not supported for this project.\t\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: Accelerators are not supported for this project.\n",
      "    field: job_spec.worker_pool_specs[0].machine_spec.accelerator_count\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'echo $JOB_DIR $REGION $JOB_NAME\\n\\nPYTHON_PACKAGE_URIS=gs://${BUCKET}/cloud_training/chest_xray-0.1.tar.gz\\nMACHINE_TYPE=n1-highcpu-16\\nREPLICA_COUNT=1\\nPYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-6:latest\"\\nPYTHON_MODULE=trainer.task\\n    \\nWORKER_POOL_SPEC=\"machine-type=$MACHINE_TYPE,\\\\\\nreplica-count=$REPLICA_COUNT,\\\\\\nexecutor-image-uri=$PYTHON_PACKAGE_EXECUTOR_IMAGE_URI,\\\\\\naccelerator-type=NVIDIA_TESLA_K80,\\\\\\naccelerator-count=2,\\\\\\npython-module=$PYTHON_MODULE\"\\n\\ngcloud ai custom-jobs create \\\\\\n  --region=${REGION} \\\\\\n  --display-name=$JOB_NAME \\\\\\n  --python-package-uris=$PYTHON_PACKAGE_URIS \\\\\\n  --worker-pool-spec=$WORKER_POOL_SPEC \\\\\\n  --args=\"--job-dir=$JOB_DIR,--model_type=$MODEL_TYPE --nrows=2000\"\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24456/2739537513.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'echo $JOB_DIR $REGION $JOB_NAME\\n\\nPYTHON_PACKAGE_URIS=gs://${BUCKET}/cloud_training/chest_xray-0.1.tar.gz\\nMACHINE_TYPE=n1-highcpu-16\\nREPLICA_COUNT=1\\nPYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-6:latest\"\\nPYTHON_MODULE=trainer.task\\n    \\nWORKER_POOL_SPEC=\"machine-type=$MACHINE_TYPE,\\\\\\nreplica-count=$REPLICA_COUNT,\\\\\\nexecutor-image-uri=$PYTHON_PACKAGE_EXECUTOR_IMAGE_URI,\\\\\\naccelerator-type=NVIDIA_TESLA_K80,\\\\\\naccelerator-count=2,\\\\\\npython-module=$PYTHON_MODULE\"\\n\\ngcloud ai custom-jobs create \\\\\\n  --region=${REGION} \\\\\\n  --display-name=$JOB_NAME \\\\\\n  --python-package-uris=$PYTHON_PACKAGE_URIS \\\\\\n  --worker-pool-spec=$WORKER_POOL_SPEC \\\\\\n  --args=\"--job-dir=$JOB_DIR,--model_type=$MODEL_TYPE --nrows=2000\"\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2404\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2406\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2407\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'echo $JOB_DIR $REGION $JOB_NAME\\n\\nPYTHON_PACKAGE_URIS=gs://${BUCKET}/cloud_training/chest_xray-0.1.tar.gz\\nMACHINE_TYPE=n1-highcpu-16\\nREPLICA_COUNT=1\\nPYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-6:latest\"\\nPYTHON_MODULE=trainer.task\\n    \\nWORKER_POOL_SPEC=\"machine-type=$MACHINE_TYPE,\\\\\\nreplica-count=$REPLICA_COUNT,\\\\\\nexecutor-image-uri=$PYTHON_PACKAGE_EXECUTOR_IMAGE_URI,\\\\\\naccelerator-type=NVIDIA_TESLA_K80,\\\\\\naccelerator-count=2,\\\\\\npython-module=$PYTHON_MODULE\"\\n\\ngcloud ai custom-jobs create \\\\\\n  --region=${REGION} \\\\\\n  --display-name=$JOB_NAME \\\\\\n  --python-package-uris=$PYTHON_PACKAGE_URIS \\\\\\n  --worker-pool-spec=$WORKER_POOL_SPEC \\\\\\n  --args=\"--job-dir=$JOB_DIR,--model_type=$MODEL_TYPE --nrows=2000\"\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $JOB_DIR $REGION $JOB_NAME\n",
    "\n",
    "PYTHON_PACKAGE_URIS=gs://${BUCKET}/cloud_training/chest_xray-0.1.tar.gz\n",
    "MACHINE_TYPE=n1-highcpu-16\n",
    "REPLICA_COUNT=1\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-6:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "    \n",
    "WORKER_POOL_SPEC=\"machine-type=$MACHINE_TYPE,\\\n",
    "replica-count=$REPLICA_COUNT,\\\n",
    "executor-image-uri=$PYTHON_PACKAGE_EXECUTOR_IMAGE_URI,\\\n",
    "accelerator-type=NVIDIA_TESLA_K80,\\\n",
    "accelerator-count=2,\\\n",
    "python-module=$PYTHON_MODULE\"\n",
    "\n",
    "gcloud ai custom-jobs create \\\n",
    "  --region=${REGION} \\\n",
    "  --display-name=$JOB_NAME \\\n",
    "  --python-package-uris=$PYTHON_PACKAGE_URIS \\\n",
    "  --worker-pool-spec=$WORKER_POOL_SPEC \\\n",
    "  --args=\"--job-dir=$JOB_DIR,--model_type=$MODEL_TYPE --nrows=2000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4ca26-7c76-49fd-bbae-7f2af798e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "SAVEDMODEL_DIR=${JOB_DIR}keras_export\n",
    "echo $SAVEDMODEL_DIR\n",
    "gsutil ls $SAVEDMODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9692096-a244-4ee6-915d-adf53e0db0b7",
   "metadata": {},
   "source": [
    "# Deploying and Predicting with the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d987a-1d49-42fb-9d3f-b55ff8d94dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
